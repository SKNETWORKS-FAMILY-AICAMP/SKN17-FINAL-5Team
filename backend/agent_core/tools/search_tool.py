"""
ë¬´ì—­ ë¬¸ì„œ ê²€ìƒ‰ Tool

ë³µí•© ì§ˆë¬¸ë„ ì²˜ë¦¬í•  ìˆ˜ ìˆë„ë¡ ì¿¼ë¦¬ ë³€í™˜ + ë³‘ë ¬ ê²€ìƒ‰ ê¸°ëŠ¥ ì¶”ê°€
- ì¿¼ë¦¬ ê°œì„ : "ë¬´ì—­ ì‚¬ê¸° ë°©ì§€ ì–´ë–»ê²Œ í•´?" â†’ "ë¬´ì—­ ì‚¬ê¸° ì˜ˆë°© ë° ëŒ€ì‘ ë°©ë²•"
- ë³µí•© ì§ˆë¬¸ ë¶„í•´: "ìˆ˜ì¶œê³¼ ìˆ˜ì… ì°¨ì´" â†’ ["ìˆ˜ì¶œ ì ˆì°¨", "ìˆ˜ì… ì ˆì°¨"] 2ê°œë¡œ ë‚˜ëˆ ì„œ ê²€ìƒ‰
- ë³‘ë ¬ ê²€ìƒ‰: ì—¬ëŸ¬ ì„œë¸Œì¿¼ë¦¬ë¥¼ ë™ì‹œì— ê²€ìƒ‰í•´ì„œ ì†ë„ í–¥ìƒ
- Reranking: ìµœì¢…ì ìœ¼ë¡œ ê´€ë ¨ë„ ë†’ì€ ë¬¸ì„œë§Œ Agentì—ê²Œ ì „ë‹¬
"""

import asyncio
from typing import List
from agents import function_tool

from agent_core.config import (
    qdrant_client,
    openai_client,
    COLLECTION_NAME,
    COLLECTION_USER_DOCS,
    EMBEDDING_MODEL,
    USE_RERANKER,
    USE_PER_QUERY_RERANK
)
from agent_core.utils import print_retrieved_documents
from agent_core.services.reranker_service import call_reranker_api
from agent_core.services.query_transformer_service import rewrite_and_decompose_query


@function_tool
async def search_trade_documents(query: str, limit: int = 25, top_k: int = 10) -> str:
    """
    ë¬´ì—­ ë¬¸ì„œ ê²€ìƒ‰ ë©”ì¸ í•¨ìˆ˜

    ë‹¨ìˆœ ì§ˆë¬¸("ìˆ˜ì¶œ ì ˆì°¨ëŠ”?")ë„, ë³µí•© ì§ˆë¬¸("ìˆ˜ì¶œê³¼ ìˆ˜ì… ì°¨ì´ëŠ”?")ë„ ëª¨ë‘ ì²˜ë¦¬ ê°€ëŠ¥

    Args:
        query: ì‚¬ìš©ì ì§ˆë¬¸
        limit: Qdrantì—ì„œ ê°€ì ¸ì˜¬ ë¬¸ì„œ ìˆ˜ (ê¸°ë³¸ 25ê°œ)
        top_k: ìµœì¢…ì ìœ¼ë¡œ Agentì—ê²Œ ì „ë‹¬í•  ë¬¸ì„œ ìˆ˜ (ê¸°ë³¸ 5ê°œ)

    Returns:
        Agentê°€ ì½ì„ ìˆ˜ ìˆê²Œ í¬ë§·ëœ ë¬¸ì„œ í…ìŠ¤íŠ¸
    """
    print(f"\nğŸ” ê²€ìƒ‰ ì‹œì‘: '{query}' (ì´ˆê¸° ê²€ìƒ‰: {limit}ê°œ, ìµœì¢… ì„ ì •: {top_k}ê°œ)")

    # ì¿¼ë¦¬ ê°œì„  + í•„ìš”í•˜ë©´ ë³µí•© ì§ˆë¬¸ ë¶„í•´
    transform = await rewrite_and_decompose_query(query)
    rewritten_query = transform.rewritten_query
    sub_queries = transform.sub_queries or [rewritten_query]  # Noneì´ë©´ ë‹¨ì¼ ì¿¼ë¦¬ë¡œ ë³€í™˜

    # ===== í†µí•© ê²€ìƒ‰ (ë‹¨ìˆœ/ë³µí•© ì§ˆë¬¸ ëª¨ë‘ ë™ì¼í•œ ê²½ë¡œ ì‚¬ìš©) =====
    grouped_points = await _multi_search(sub_queries, limit)
    total_docs = sum(len(pts) for pts in grouped_points.values())
    print(f"âœ“ ìµœì¢… {total_docs}ê°œ ë¬¸ì„œ ìˆ˜ì§‘ ({len(sub_queries)}ê°œ ê·¸ë£¹)\n")

    if not grouped_points or all(len(pts) == 0 for pts in grouped_points.values()):
        print("âš ï¸  ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\n")
        return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

    # ë””ë²„ê¹…ìš© ì¶œë ¥
    all_points_for_debug = []
    for pts in grouped_points.values():
        all_points_for_debug.extend(pts)
    print_retrieved_documents(all_points_for_debug, n=25)

    # ----- ê°œë³„ Rerank vs í†µí•© Rerank ì„ íƒ -----
    if USE_RERANKER and USE_PER_QUERY_RERANK:
        # ê°œë³„ Rerank: ê° ì„œë¸Œ ì¿¼ë¦¬ë³„ë¡œ rerank
        reranked_results = await _rerank_per_query(grouped_points, sub_queries, top_k)

        if not reranked_results:
            print("âš ï¸  Rerank ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\n")
            return "ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤."

        # ê²°ê³¼ í¬ë§·íŒ… (ê°œë³„ rerank ê²°ê³¼)
        print("="*60)
        print(f"ğŸ¯ ê°œë³„ Rerankë¡œ ì„ ì •ëœ ìµœì¢… {len(reranked_results)}ê°œ ë¬¸ì„œ (ëª¨ë¸ì—ê²Œ ì „ë‹¬)")
        print("="*60)

        formatted = []
        for rank, (point, rerank_score, sub_query) in enumerate(reranked_results, 1):
            content = point.payload.get("text") or point.payload.get("content") or ""
            if content:
                content = content[:500]
            source_tag = point.payload.get("doc_id", "unknown")

            # Agentì—ê²Œ ì „ë‹¬í•  í…ìŠ¤íŠ¸
            doc_text = f"[{rank}] {content}\n   ì¶œì²˜: {source_tag}, Rerank ì ìˆ˜: {rerank_score:.3f}, ì„œë¸Œì¿¼ë¦¬: '{sub_query}'"
            formatted.append(doc_text)

            # ì½˜ì†” ë””ë²„ê¹… ì¶œë ¥
            debug_doc_name = point.payload.get("document_name") or point.payload.get("file_name")
            debug_article = point.payload.get("article")

            print(f"\në¬¸ì„œ {rank}:")
            print(f"  ì„œë¸Œì¿¼ë¦¬: '{sub_query}'")
            print(f"  ì¶œì²˜: {source_tag}")
            if debug_doc_name:
                print(f"  íŒŒì¼ëª…: {debug_doc_name}")
            if debug_article:
                print(f"  ì¡°ë¬¸: {debug_article}")
            print(f"  Rerank ì ìˆ˜: {rerank_score:.3f}")
            print(f"  ë‚´ìš©: {content[:200]}{'...' if len(content) > 200 else ''}")

    else:
        # í†µí•© Rerank ë˜ëŠ” Reranker ë¯¸ì‚¬ìš©

        # ëª¨ë“  ê·¸ë£¹ì˜ ë¬¸ì„œë¥¼ ë³‘í•©
        seen_ids = {}
        for pts in grouped_points.values():
            for point in pts:
                if point.id not in seen_ids or point.score > seen_ids[point.id].score:
                    seen_ids[point.id] = point

        all_points = sorted(seen_ids.values(), key=lambda p: p.score, reverse=True)

        rerank_response = None
        if USE_RERANKER:
            # í†µí•© Rerank ë°©ì‹
            num_queries = len(sub_queries)
            rerank_msg = f"â„¹ï¸  í†µí•© Rerank ë°©ì‹ ì‚¬ìš© ({num_queries}ê°œ ì¿¼ë¦¬ ë³‘í•©)\n"
            print(rerank_msg)

            documents_for_rerank = [
                point.payload.get("text") or point.payload.get("content") or ""
                for point in all_points
            ]

            try:
                rerank_response = await call_reranker_api(rewritten_query, documents_for_rerank, top_k=top_k)
            except Exception as e:
                print(f"âš ï¸  Reranker ì‹¤íŒ¨: {e}")
                print(f"âš ï¸  ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼ì˜ ìƒìœ„ {top_k}ê°œë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n")
        else:
            # Reranker ë¯¸ì‚¬ìš©
            print(f"â„¹ï¸  Reranker ë¯¸ì‚¬ìš© - ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼ ìƒìœ„ {top_k}ê°œ ì‚¬ìš©\n")

        # ê²°ê³¼ í¬ë§·íŒ…
        formatted = _format_rerank_results(all_points, rerank_response, top_k)

    print("\n" + "=" * 60)
    print("ğŸ¤– ëª¨ë¸ì´ ìœ„ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„± ì¤‘...")
    print("=" * 60 + "\n")

    return "\n\n".join(formatted)


# ===== ë‚´ë¶€ í—¬í¼ í•¨ìˆ˜ =====

async def _multi_search(sub_queries: List[str], limit: int) -> dict:
    """
    ë³‘ë ¬ ê²€ìƒ‰ (ë‹¨ì¼/ë³µí•© ì§ˆë¬¸ ëª¨ë‘ ì²˜ë¦¬)

    ì˜ˆ1 (ë‹¨ì¼): ["ìˆ˜ì¶œ ì ˆì°¨"] 1ê°œ ê²€ìƒ‰
    ì˜ˆ2 (ë³µí•©): ["ìˆ˜ì¶œ ì ˆì°¨", "ìˆ˜ì… ì ˆì°¨"] 2ê°œë¥¼ ë™ì‹œì— ê²€ìƒ‰ â†’ ì„œë¸Œ ì¿¼ë¦¬ë³„ ê·¸ë£¹í™”

    ìˆœì°¨ ê²€ìƒ‰ë³´ë‹¤ 2~3ë°° ë¹ ë¦„ (asyncio.gather ë•ë¶„)

    Returns:
        Dict[str, List]: {ì„œë¸Œì¿¼ë¦¬: ê²€ìƒ‰ê²°ê³¼Points} í˜•íƒœì˜ ë”•ì…”ë„ˆë¦¬
    """
    num_queries = len(sub_queries)
    query_type = "ë‹¨ì¼ ì¿¼ë¦¬" if num_queries == 1 else f"{num_queries}ê°œ ì„œë¸Œì¿¼ë¦¬"
    print(f"ğŸ“Œ ê²€ìƒ‰ ìˆ˜í–‰ ({query_type})")

    # 1) ëª¨ë“  ì„œë¸Œì¿¼ë¦¬ë¥¼ ë™ì‹œì— ë²¡í„°ë¡œ ë³€í™˜ (ë³‘ë ¬ ì²˜ë¦¬)
    print("   Step 1: Embedding ìƒì„± ì¤‘...")
    embedding_tasks = [
        asyncio.to_thread(  # ë™ê¸° í•¨ìˆ˜ë¥¼ ë¹„ë™ê¸°ë¡œ ê°ì‹¸ê¸°
            openai_client.embeddings.create,
            model=EMBEDDING_MODEL,
            input=sq
        )
        for sq in sub_queries
    ]
    embeddings = await asyncio.gather(*embedding_tasks)  # ëª¨ë‘ ì™„ë£Œë  ë•Œê¹Œì§€ ëŒ€ê¸°

    # 2) ëª¨ë“  ë²¡í„°ë¡œ ë™ì‹œì— Qdrant ê²€ìƒ‰ (ë³‘ë ¬ ì²˜ë¦¬)
    print("   Step 2: Qdrant ê²€ìƒ‰ ì¤‘...")
    search_tasks = [
        asyncio.to_thread(
            qdrant_client.query_points,
            collection_name=COLLECTION_NAME,
            query=emb.data[0].embedding,
            limit=limit,
            with_payload=True
        )
        for emb in embeddings
    ]
    search_results = await asyncio.gather(*search_tasks)

    # 3) ì„œë¸Œ ì¿¼ë¦¬ë³„ë¡œ ê·¸ë£¹í™”
    print("   Step 3: ì„œë¸Œ ì¿¼ë¦¬ë³„ ê·¸ë£¹í™” ì¤‘...")
    grouped_points = {}

    for sq, result in zip(sub_queries, search_results):
        points = result.points if hasattr(result, 'points') else []

        # ê° ê·¸ë£¹ ë‚´ ì¤‘ë³µ ì œê±° (ê°™ì€ ì„œë¸Œì¿¼ë¦¬ ë‚´ì—ì„œë§Œ)
        seen_ids = {}
        for point in points:
            point_id = point.id
            if point_id not in seen_ids or point.score > seen_ids[point_id].score:
                seen_ids[point_id] = point

        # ì ìˆ˜ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
        unique_points = sorted(seen_ids.values(), key=lambda p: p.score, reverse=True)
        grouped_points[sq] = unique_points

        print(f"   ì„œë¸Œì¿¼ë¦¬: '{sq}' â†’ {len(unique_points)}ê°œ")

    return grouped_points


def _format_rerank_results(points: List, rerank_response, top_k: int) -> List[str]:
    """
    Rerank ê²°ê³¼ë¥¼ Agentì—ê²Œ ì „ë‹¬í•  í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…

    Args:
        points: ê²€ìƒ‰ëœ ë¬¸ì„œ Points ë¦¬ìŠ¤íŠ¸
        rerank_response: Reranker API ì‘ë‹µ (Noneì´ë©´ ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼ ì‚¬ìš©)
        top_k: ë°˜í™˜í•  ë¬¸ì„œ ê°œìˆ˜

    Returns:
        List[str]: í¬ë§·íŒ…ëœ ë¬¸ì„œ í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸
    """
    formatted = []

    if rerank_response:
        # Reranker ê²°ê³¼ ì‚¬ìš©
        print("="*60)
        print(f"ğŸ¯ Rerankerë¡œ ì„ ì •ëœ ìµœì¢… {len(rerank_response.results)}ê°œ ë¬¸ì„œ (ëª¨ë¸ì—ê²Œ ì „ë‹¬)")
        print("="*60)

        for rank, result in enumerate(rerank_response.results, 1):
            original_point = points[result.index]
            content = original_point.payload.get("text") or original_point.payload.get("content") or ""
            if content:
                content = content[:500]  # ë„ˆë¬´ ê¸¸ë©´ ì˜ë¼ëƒ„
            source_tag = original_point.payload.get("data_source", "unknown")
            rerank_score = result.score

            # Agentì—ê²Œ ì „ë‹¬í•  í…ìŠ¤íŠ¸
            doc_text = f"[{rank}] {content}\n   ì¶œì²˜: {source_tag}, Rerank ì ìˆ˜: {rerank_score:.3f}"
            formatted.append(doc_text)

            # ì½˜ì†” ë””ë²„ê¹… ì¶œë ¥
            debug_doc_name = original_point.payload.get("document_name") or original_point.payload.get("file_name")
            debug_article = original_point.payload.get("article")

            print(f"\në¬¸ì„œ {rank}:")
            print(f"  ì¶œì²˜: {source_tag}")
            if debug_doc_name:
                print(f"  íŒŒì¼ëª…: {debug_doc_name}")
            if debug_article:
                print(f"  ì¡°ë¬¸: {debug_article}")
            print(f"  ì›ë³¸ ì¸ë±ìŠ¤: {result.index + 1}")
            print(f"  Rerank ì ìˆ˜: {rerank_score:.3f}")
            print(f"  ë‚´ìš©: {content[:200]}{'...' if len(content) > 200 else ''}")

    else:
        # ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼ ì‚¬ìš©
        print("="*60)
        print(f"ğŸ“„ ê¸°ë³¸ ê²€ìƒ‰ ê²°ê³¼ ìƒìœ„ {top_k}ê°œ (ëª¨ë¸ì—ê²Œ ì „ë‹¬)")
        print("="*60)

        for i, point in enumerate(points[:top_k], 1):
            content = point.payload.get("text") or point.payload.get("content") or ""
            if content:
                content = content[:500]
            score = point.score
            source_tag = point.payload.get("data_source", "unknown")

            doc_text = f"[{i}] {content}\n   ì¶œì²˜: {source_tag}, ì ìˆ˜: {score:.3f}"
            formatted.append(doc_text)

    return formatted


async def _rerank_per_query(grouped_points: dict, sub_queries: List[str], total_topk: int) -> List:
    """
    ê° ì„œë¸Œ ì¿¼ë¦¬ë³„ë¡œ ê°œë³„ reranking ìˆ˜í–‰

    Args:
        grouped_points: ì„œë¸Œ ì¿¼ë¦¬ë³„ë¡œ ê·¸ë£¹í™”ëœ ê²€ìƒ‰ ê²°ê³¼ {sub_query: [Points]}
        sub_queries: ì„œë¸Œ ì¿¼ë¦¬ ë¦¬ìŠ¤íŠ¸
        total_topk: ìµœì¢… ë°˜í™˜í•  ì´ ë¬¸ì„œ ê°œìˆ˜

    Returns:
        List[tuple]: [(Point, rerank_score, sub_query), ...] í˜•íƒœì˜ ë¦¬ìŠ¤íŠ¸
    """
    # Top-kë¥¼ ì„œë¸Œ ì¿¼ë¦¬ ê°œìˆ˜ë¡œ ê· ë“± ë°°ë¶„ (ìµœì†Œ 1ê°œ)
    per_query_k = max(1, total_topk // len(sub_queries))

    print(f"\nğŸ¯ ê°œë³„ Rerank ìˆ˜í–‰: {len(sub_queries)}ê°œ ì„œë¸Œ ì¿¼ë¦¬")
    print(f"   ê° ì„œë¸Œ ì¿¼ë¦¬ë‹¹ {per_query_k}ê°œ ì„ ì • (ì´ ì•½ {per_query_k * len(sub_queries)}ê°œ)")

    all_reranked = []

    for i, sq in enumerate(sub_queries, 1):
        points = grouped_points.get(sq, [])
        if not points:
            print(f"\n   [{i}/{len(sub_queries)}] '{sq}' â†’ ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ, ê±´ë„ˆëœ€")
            continue

        print(f"\n   [{i}/{len(sub_queries)}] '{sq}'")
        print(f"      ê²€ìƒ‰ ê²°ê³¼: {len(points)}ê°œ â†’ Rerank â†’ top {per_query_k}")

        # ë¬¸ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        documents = [
            point.payload.get("text") or point.payload.get("content") or ""
            for point in points
        ]

        # ê°œë³„ rerank ìˆ˜í–‰
        try:
            rerank_response = await call_reranker_api(sq, documents, top_k=per_query_k)

            # ê²°ê³¼ ì €ì¥ (ì›ë³¸ Point, rerank ì ìˆ˜, ì„œë¸Œ ì¿¼ë¦¬)
            for result in rerank_response.results:
                original_point = points[result.index]
                all_reranked.append((original_point, result.score, sq))

            print(f"      âœ“ Rerank ì™„ë£Œ: {len(rerank_response.results)}ê°œ ì„ ì •")

        except Exception as e:
            print(f"      âš ï¸ Rerank ì‹¤íŒ¨: {e}")
            print(f"      â†’ ê¸°ë³¸ ê²€ìƒ‰ ì ìˆ˜ ê¸°ì¤€ ìƒìœ„ {per_query_k}ê°œ ì‚¬ìš©")
            # ì‹¤íŒ¨ ì‹œ ê²€ìƒ‰ ì ìˆ˜ ê¸°ì¤€ ìƒìœ„ per_query_kê°œ ì‚¬ìš©
            for point in points[:per_query_k]:
                all_reranked.append((point, point.score, sq))

    print(f"\nâœ“ ê°œë³„ Rerank ì™„ë£Œ: ì´ {len(all_reranked)}ê°œ ë¬¸ì„œ ì„ ì •\n")

    return all_reranked


# ===== ì‚¬ìš©ì ì—…ë¡œë“œ ë¬¸ì„œ ê²€ìƒ‰ =====

@function_tool
async def search_user_document(document_id: int, query: str, limit: int = 10) -> str:
    """
    íŠ¹ì • ì‚¬ìš©ì ì—…ë¡œë“œ ë¬¸ì„œ ë‚´ì—ì„œ ê²€ìƒ‰

    Args:
        document_id: ê²€ìƒ‰í•  ë¬¸ì„œ ID (UserDocument.id)
        query: ì‚¬ìš©ì ì§ˆë¬¸
        limit: ë°˜í™˜í•  ìµœëŒ€ ë¬¸ì„œ ìˆ˜ (ê¸°ë³¸ 10ê°œ)

    Returns:
        Agentê°€ ì½ì„ ìˆ˜ ìˆê²Œ í¬ë§·ëœ ë¬¸ì„œ í…ìŠ¤íŠ¸
    """
    from qdrant_client.models import Filter, FieldCondition, MatchValue

    print(f"\nğŸ” ë¬¸ì„œ ë‚´ ê²€ìƒ‰: document_id={document_id}, query='{query}', limit={limit}")

    try:
        # 1. Query embedding ìƒì„±
        print("   Step 1: Embedding ìƒì„± ì¤‘...")
        embedding_response = await asyncio.to_thread(
            openai_client.embeddings.create,
            model=EMBEDDING_MODEL,
            input=query
        )
        query_vector = embedding_response.data[0].embedding

        # 2. Qdrant ê²€ìƒ‰ (document_id í•„í„° ì ìš©)
        print(f"   Step 2: Qdrant ê²€ìƒ‰ ì¤‘ (collection: {COLLECTION_USER_DOCS})...")
        search_result = await asyncio.to_thread(
            qdrant_client.query_points,
            collection_name=COLLECTION_USER_DOCS,
            query=query_vector,
            query_filter=Filter(
                must=[
                    FieldCondition(
                        key="doc_id",
                        match=MatchValue(value=document_id)
                    )
                ]
            ),
            limit=limit,
            with_payload=True
        )

        points = search_result.points if hasattr(search_result, 'points') else []

        if not points:
            print("âš ï¸  ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.\n")
            return "ì´ ë¬¸ì„œì—ì„œ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        print(f"âœ“ {len(points)}ê°œ ì²­í¬ ê²€ìƒ‰ë¨\n")

        # 3. ê²°ê³¼ í¬ë§·íŒ…
        formatted = []
        print("="*60)
        print(f"ğŸ“„ ê²€ìƒ‰ëœ ë¬¸ì„œ ì²­í¬ ({len(points)}ê°œ)")
        print("="*60)

        for rank, point in enumerate(points, 1):
            text = point.payload.get("text", "")
            page = point.payload.get("page", "?")
            score = point.score

            # Agentì—ê²Œ ì „ë‹¬í•  í…ìŠ¤íŠ¸
            doc_text = f"[í˜ì´ì§€ {page}] {text}\n   (ê´€ë ¨ë„: {score:.3f})"
            formatted.append(doc_text)

            # ì½˜ì†” ë””ë²„ê¹… ì¶œë ¥
            print(f"\nì²­í¬ {rank}:")
            print(f"  í˜ì´ì§€: {page}")
            print(f"  ì ìˆ˜: {score:.3f}")
            print(f"  ë‚´ìš©: {text[:200]}{'...' if len(text) > 200 else ''}")

        print("\n" + "=" * 60)
        print("ğŸ¤– ëª¨ë¸ì´ ìœ„ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€ ìƒì„± ì¤‘...")
        print("=" * 60 + "\n")

        return "\n\n".join(formatted)

    except Exception as e:
        print(f"âŒ ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
